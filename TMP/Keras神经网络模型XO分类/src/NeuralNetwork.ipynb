{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络XO字符分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入数据\n",
    "\n",
    "序列化文件转换为数据集对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dataset = None\n",
    "\n",
    "with open('../../common/xo_dataset.bin', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集图像向量\n",
    "X_train = dataset['X_train']\n",
    "# 训练集标签\n",
    "y_train = dataset['y_train']\n",
    "# 测试集图像向量\n",
    "X_test = dataset['X_test']\n",
    "# 测试集标签\n",
    "y_test = dataset['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入数据格式转换为float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化，数据缩放在0-1之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label转换为one-hot格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "NB_CLASSES = 2  # 输出的类的个数　(X or O)\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入向量的维度\n",
    "RESHAPED = 784\n",
    "# 每层隐藏层神经元的个数\n",
    "N_HIDDEN = 128\n",
    "# DROPOUT的比例\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 117,250\n",
      "Trainable params: 117,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 第一层隐藏层 全连接层\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "# Relu激活层\n",
    "model.add(Activation('relu'))\n",
    "# Dropout层，随机删除神经元\n",
    "# 网络表现力强，而且可以防止过拟合\n",
    "# 注:K210不支持Dropout层，所以注释掉这部分\n",
    "# model.add(Dropout(DROPOUT))\n",
    "# 第二层隐藏层 全连接层\n",
    "model.add(Dense(N_HIDDEN))\n",
    "# Relu激活层\n",
    "model.add(Activation('relu'))\n",
    "# Dropout层，随机删除神经元\n",
    "# model.add(Dropout(DROPOUT))\n",
    "# 全连接层，两个神经元　与输出尺寸一致\n",
    "model.add(Dense(NB_CLASSES))\n",
    "# Softmax正规化\n",
    "# 使得输出结果范围在0-1之间, 而且所有的输出层结果数值相加=1\n",
    "# 相当于每个输出代表是这个类的概率\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "#　当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一个 epoch。\n",
    "NB_EPOCH = 20\n",
    "# 当一个 epoch 对于计算机而言太庞大的时候，就需要把它分成多个小块，每个小块称之为一个batch\n",
    "# BATCH_SIZE 是一个 batch 中的样本总数\n",
    "BATCH_SIZE = 128\n",
    "# optimizer参数优化器　效果比随机梯度下降(SGD)好\n",
    "OPTIMIZER = RMSprop()\n",
    "\n",
    "VERBOSE = 1\n",
    "# 分隔验证数据比例\n",
    "# 从训练数据选取20%作为验证数据\n",
    "# 注: 调整超参数的时候，必须使用超参数专用的确认数据. 用于调整超参数的数据，一般称之为超参数\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7680 samples, validate on 1920 samples\n",
      "Epoch 1/20\n",
      "7680/7680 [==============================] - 1s 72us/step - loss: 0.0497 - acc: 0.9818 - val_loss: 0.0144 - val_acc: 0.9953\n",
      "Epoch 2/20\n",
      "7680/7680 [==============================] - 0s 56us/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 3/20\n",
      "7680/7680 [==============================] - 0s 43us/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0114 - val_acc: 0.9964\n",
      "Epoch 4/20\n",
      "7680/7680 [==============================] - 0s 40us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0094 - val_acc: 0.9979\n",
      "Epoch 5/20\n",
      "7680/7680 [==============================] - 0s 39us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0069 - val_acc: 0.9979\n",
      "Epoch 6/20\n",
      "7680/7680 [==============================] - 0s 36us/step - loss: 3.9910e-04 - acc: 0.9999 - val_loss: 0.0107 - val_acc: 0.9984\n",
      "Epoch 7/20\n",
      "7680/7680 [==============================] - 0s 35us/step - loss: 3.4937e-04 - acc: 0.9999 - val_loss: 0.0101 - val_acc: 0.9979\n",
      "Epoch 8/20\n",
      "7680/7680 [==============================] - 0s 36us/step - loss: 7.2327e-05 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9964\n",
      "Epoch 9/20\n",
      "7680/7680 [==============================] - 0s 37us/step - loss: 1.8869e-04 - acc: 0.9999 - val_loss: 0.0144 - val_acc: 0.9974\n",
      "Epoch 10/20\n",
      "7680/7680 [==============================] - 0s 35us/step - loss: 8.5376e-05 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9969\n",
      "Epoch 11/20\n",
      "7680/7680 [==============================] - 0s 36us/step - loss: 5.9034e-06 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9979\n",
      "Epoch 12/20\n",
      "7680/7680 [==============================] - 0s 36us/step - loss: 1.3686e-06 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9964\n",
      "Epoch 13/20\n",
      "7680/7680 [==============================] - 0s 37us/step - loss: 2.4152e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9984\n",
      "Epoch 14/20\n",
      "7680/7680 [==============================] - 0s 38us/step - loss: 2.1532e-07 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9984\n",
      "Epoch 15/20\n",
      "7680/7680 [==============================] - 0s 37us/step - loss: 1.4702e-07 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9984\n",
      "Epoch 16/20\n",
      "7680/7680 [==============================] - 0s 37us/step - loss: 1.2677e-07 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9984\n",
      "Epoch 17/20\n",
      "7680/7680 [==============================] - 0s 38us/step - loss: 1.2366e-07 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9984\n",
      "Epoch 18/20\n",
      "7680/7680 [==============================] - 0s 35us/step - loss: 1.2142e-07 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9984\n",
      "Epoch 19/20\n",
      "7680/7680 [==============================] - 0s 40us/step - loss: 1.2075e-07 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9984\n",
      "Epoch 20/20\n",
      "7680/7680 [==============================] - 0s 40us/step - loss: 1.2037e-07 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9984\n",
      "1600/1600 [==============================] - 0s 30us/step\n",
      "\n",
      "Test score: 0.03620177447206174\n",
      "Test accuracy: 0.995\n"
     ]
    }
   ],
   "source": [
    "# 模型编译\n",
    "# 损失函数为种类交叉熵　Categorical Crossentropy\n",
    "# metrics 评价函数用于评估当前训练模型的性能 这里标准选用了准确率\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 数据拟合，记录保存在history中\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "# 模型评估，得分存在score里面\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练可视化\n",
    "\n",
    "可视化训练结果的目的，主要是为了观察超参数，模型是否产生了过拟合的现象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "历史记录里面有四个指标\n",
    "* `acc` 测试集的准确率\n",
    "* `val_acc` 验证集的准确率\n",
    "* `loss` 训练集上的loss\n",
    "* `val_loss` 验证机上的loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数就是人为预先设定的参数，例如：\n",
    "1. EPOCH的大小\n",
    "2. BATCH的大小\n",
    "3. 隐藏层神经元的个数\n",
    "4. 隐藏层的层数\n",
    "5. 优化器的选择\n",
    "6. DROPOUT的比例\n",
    "等等．\n",
    "\n",
    "超参数优化就是尝试不同的超参数组合，找到得分最高的那个．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH = 3\n",
    "BATCH_SIZE = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7680 samples, validate on 1920 samples\n",
      "Epoch 1/3\n",
      "7680/7680 [==============================] - 0s 60us/step - loss: 1.1999e-07 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9979\n",
      "Epoch 2/3\n",
      "7680/7680 [==============================] - 0s 36us/step - loss: 1.1986e-07 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9979\n",
      "Epoch 3/3\n",
      "7680/7680 [==============================] - 0s 35us/step - loss: 1.1976e-07 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9979\n",
      "1600/1600 [==============================] - 0s 26us/step\n",
      "\n",
      "Test score: 0.03558672004053449\n",
      "Test accuracy: 0.99625\n"
     ]
    }
   ],
   "source": [
    "# 模型编译\n",
    "# 损失函数为种类交叉熵　Categorical Crossentropy\n",
    "# metrics 评价函数用于评估当前训练模型的性能 这里标准选用了准确率\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 数据拟合，记录保存在history中\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "# 模型评估，得分存在score里面\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微调后，虽然测试集上的准确率没有发生太大变化，还是`0.99625`, 但是大幅度降低了训练次数还有训练时间．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../common/nn_model.bin', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Keras深度学习实战, Antonio Gulli, Sujit Pal\n",
    "\n",
    "[神经网络训练中，傻傻分不清Epoch、Batch Size和迭代](https://www.jiqizhixin.com/articles/2017-09-25-3\n",
    ")\n",
    "\n",
    "[keras深度学习框架输出acc/loss,val_acc/val_loss，什么意思？](https://www.zhihu.com/question/58200419)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
